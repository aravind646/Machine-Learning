function theta = minimize(f, init_theta)
% MINIMIZE  Find a local minima of a function f, starting at init_theta.
%          f - function to be minimized. f should be of the form:
%              [cost, grad(, hess)] = f(theta)
    tol = 1e-5; % you should stop optimization when the absolute difference
                % in cost between two iterations is less than tol.
                
    maxIter = 1000; % you should alternatively break after maxIter.
    alpha = 0.1;
    alpha_decay = 0.998;
    % Write your solution below. You should use either gradient descent or
    % Newton-Raphson to find the (local) minimum of the function.
    % Our solution is ~10 lines
    %% BEGIN SOLUTION (GRADIENT DESCENT)        
    old_theta = init_theta;
    [cost, grad] = f(old_theta);
    old_cost = cost;
    old_cost
    grad
    
    for i = 2:maxIter         
        old_theta = old_theta - (alpha*(alpha_decay * old_cost));
         [cost, grad] = f(old_theta);
         new_cost = cost;   
         disp('abs')
         disp(abs(old_cost - new_cost))
         disp(tol)
         if (abs(old_cost - new_cost) < tol)
            disp('should break now')
            %break        
         end                 
         old_cos
    end
    
    disp('outside of for')
 %   for i = 2:maxIter
  %      newCost = costLR(f.y, f.dy, init_theta, f.ddy);
   %     if (abs(oldCost - newCost) < tol)
    %        break        
     %   end
      %  oldCost = newCost;
    %end
  
    %% BEGIN SOLUTION (NEWTON'S METHOD)
  
    %% END SOLUTION
end
